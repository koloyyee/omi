n - n parameter to generate multiple messages choices.
top_p - the model considers the results of the tokens with top_p probability mass
max_tokens - The maximum number of tokens that can be generated in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length
logit_bias - Modify the likelihood of specified tokens appearing in the completion.